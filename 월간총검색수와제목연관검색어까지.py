#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  APIì™€ ì—°ê´€ê²€ìƒ‰ì–´ë¥¼ í™œìš©í•œ í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ ì¡°íšŒ ë° ë¸”ë¡œê·¸ ì œëª© ì¶”ì²œ ë„êµ¬
ì›”ê°„ì´ê²€ìƒ‰ìˆ˜ì™€ì œëª©ì—°ê´€ê²€ìƒ‰ì–´ê¹Œì§€.py

ì‚¬ìš©ë²•:
    python ì›”ê°„ì´ê²€ìƒ‰ìˆ˜ì™€ì œëª©ì—°ê´€ê²€ìƒ‰ì–´ê¹Œì§€.py "ê²€ìƒ‰í•  í‚¤ì›Œë“œ"
    python ì›”ê°„ì´ê²€ìƒ‰ìˆ˜ì™€ì œëª©ì—°ê´€ê²€ìƒ‰ì–´ê¹Œì§€.py "ê½ƒë°°ë‹¬,flower,í™”í™˜"
"""

import hashlib
import hmac
import base64
import time
import requests
import json
import sys
import urllib.parse
from urllib.parse import quote
from datetime import datetime
import os
import csv
import random
import re

# BeautifulSoup import ì‹œë„
try:
    from bs4 import BeautifulSoup
    BS4_AVAILABLE = True
except ImportError:
    BS4_AVAILABLE = False
    print("BeautifulSoup4ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install beautifulsoup4ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")

# pandasê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ëŒ€ì²´ í•¨ìˆ˜ë“¤
try:
    import pandas as pd
    PANDAS_AVAILABLE = True
    print("[OK] pandasê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
except ImportError:
    PANDAS_AVAILABLE = False
    print("[WARNING] pandasê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")
    print("[TIP] pandasë¥¼ ì„¤ì¹˜í•˜ë ¤ë©´: pip install pandas openpyxl")

# ë„¤ì´ë²„ ê²€ìƒ‰ API í´ë¼ì´ì–¸íŠ¸ ì •ë³´ (ë¬¸ì„œìˆ˜ ê²€ìƒ‰ìš©)
NAVER_CLIENT_ID = "tth9fnsKBgcMDWVf96EV"
NAVER_CLIENT_SECRET = "tgW9pUVIRc"

class NaverRelatedKeywordExtractor:
    """ë„¤ì´ë²„ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì—°ê´€ ê²€ìƒ‰ì–´ë¥¼ ì¶”ì¶œí•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.base_url = "https://search.naver.com/search.naver"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
    
    def search_naver(self, keyword):
        """
        ë„¤ì´ë²„ì—ì„œ í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰í•˜ê³  HTML ì‘ë‹µì„ ë°˜í™˜
        
        Args:
            keyword (str): ê²€ìƒ‰í•  í‚¤ì›Œë“œ
            
        Returns:
            str: HTML ì‘ë‹µ (ì‹¤íŒ¨ì‹œ None)
        """
        try:
            # URL ì¸ì½”ë”© - ë„ì–´ì“°ê¸°ì™€ íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬ ê°œì„ 
            encoded_keyword = urllib.parse.quote(keyword, safe='')
            url = f"{self.base_url}?query={encoded_keyword}"
            
            print(f"[SEARCH] ë„¤ì´ë²„ ì—°ê´€ê²€ìƒ‰ì–´ ê²€ìƒ‰ ì¤‘: {keyword}")
            
            # GET ìš”ì²­
            response = requests.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()
            
            print(f"[OK] ì—°ê´€ê²€ìƒ‰ì–´ ì‘ë‹µ ì„±ê³µ (ìƒíƒœì½”ë“œ: {response.status_code})")
            return response.text
            
        except requests.exceptions.RequestException as e:
            print(f"[ERROR] ë„¤ì´ë²„ ì—°ê´€ê²€ìƒ‰ì–´ ê²€ìƒ‰ ìš”ì²­ ì‹¤íŒ¨: {e}")
            return None
        except Exception as e:
            print(f"[ERROR] ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
            return None
    
    def extract_related_keywords_from_html(self, html_content):
        """
        HTMLì—ì„œ ì—°ê´€ ê²€ìƒ‰ì–´ë¥¼ ì¶”ì¶œ
        
        Args:
            html_content (str): ë„¤ì´ë²„ ê²€ìƒ‰ ê²°ê³¼ HTML
            
        Returns:
            list: ì—°ê´€ ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸
        """
        if not html_content:
            return []
        
        # BeautifulSoup ì‚¬ìš© ì‹œë„
        if BS4_AVAILABLE:
            return self._extract_with_beautifulsoup(html_content)
        else:
            # ì •ê·œì‹ì„ ì‚¬ìš©í•œ ëŒ€ì²´ ë°©ë²•
            return self._extract_with_regex(html_content)
    
    def _extract_with_beautifulsoup(self, html_content):
        """BeautifulSoupì„ ì‚¬ìš©í•œ ì—°ê´€ ê²€ìƒ‰ì–´ ì¶”ì¶œ"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            related_keywords = []
            
            # ì—°ê´€ ê²€ìƒ‰ì–´ ì˜ì—­ ì°¾ê¸°
            related_section = soup.find('div', class_='related_srch')
            
            if not related_section:
                print("[WARNING] ì—°ê´€ ê²€ìƒ‰ì–´ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            # ì—°ê´€ ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸ ì°¾ê¸°
            keyword_list = related_section.find('ul', class_='lst_related_srch')
            
            if not keyword_list:
                print("[WARNING] ì—°ê´€ ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            # ê° ì—°ê´€ ê²€ìƒ‰ì–´ ì¶”ì¶œ
            items = keyword_list.find_all('li', class_='item')
            
            for item in items:
                try:
                    # í‚¤ì›Œë“œ ë§í¬ ì°¾ê¸°
                    link = item.find('a', class_='keyword')
                    if link:
                        # í‚¤ì›Œë“œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                        title_div = link.find('div', class_='tit')
                        if title_div:
                            keyword = title_div.get_text(strip=True)
                            if keyword:
                                related_keywords.append(keyword)
                                print(f"  [FOUND] ì—°ê´€ ê²€ìƒ‰ì–´: {keyword}")
                except Exception as e:
                    print(f"  [WARNING] í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
                    continue
            
            return related_keywords
            
        except Exception as e:
            print(f"[ERROR] BeautifulSoup íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def _extract_with_regex(self, html_content):
        """ì •ê·œì‹ì„ ì‚¬ìš©í•œ ì—°ê´€ ê²€ìƒ‰ì–´ ì¶”ì¶œ (BeautifulSoup ëŒ€ì²´)"""
        try:
            related_keywords = []
            
            # ì—°ê´€ ê²€ìƒ‰ì–´ ì˜ì—­ ì°¾ê¸° (ì •ê·œì‹)
            related_pattern = r'<div class="tit">([^<]+)</div>'
            matches = re.findall(related_pattern, html_content)
            
            for match in matches:
                keyword = match.strip()
                if keyword and len(keyword) > 0:
                    related_keywords.append(keyword)
                    print(f"  [FOUND] ì—°ê´€ ê²€ìƒ‰ì–´: {keyword}")
            
            return related_keywords
            
        except Exception as e:
            print(f"[ERROR] ì •ê·œì‹ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def extract_related_keywords(self, keyword):
        """
        í‚¤ì›Œë“œë¡œ ë„¤ì´ë²„ ê²€ìƒ‰ í›„ ì—°ê´€ ê²€ìƒ‰ì–´ ì¶”ì¶œ
        
        Args:
            keyword (str): ê²€ìƒ‰í•  í‚¤ì›Œë“œ
            
        Returns:
            list: ì—°ê´€ ê²€ìƒ‰ì–´ ë¦¬ìŠ¤íŠ¸
        """
        print(f"\n{'='*60}")
        print(f"[SEARCH] '{keyword}' ì—°ê´€ ê²€ìƒ‰ì–´ ì¶”ì¶œ ì‹œì‘")
        print(f"{'='*60}")
        
        # ë„¤ì´ë²„ ê²€ìƒ‰
        html_content = self.search_naver(keyword)
        
        if not html_content:
            print("[ERROR] HTML ë‚´ìš©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # ì—°ê´€ ê²€ìƒ‰ì–´ ì¶”ì¶œ
        related_keywords = self.extract_related_keywords_from_html(html_content)
        
        if related_keywords:
            print(f"\n[OK] ì´ {len(related_keywords)}ê°œì˜ ì—°ê´€ ê²€ìƒ‰ì–´ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        else:
            print("\n[WARNING] ì—°ê´€ ê²€ìƒ‰ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return related_keywords

class NaverSearchAdAPI:
    """ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, api_key, secret_key, customer_id):
        self.api_key = api_key
        self.secret_key = secret_key
        self.customer_id = customer_id
        self.base_url = "https://api.searchad.naver.com"
        
    def generate_signature(self, timestamp, method, uri):
        """HMAC-SHA256 ì„œëª… ìƒì„±"""
        message = f"{timestamp}.{method}.{uri}"
        signature = hmac.new(
            self.secret_key.encode('utf-8'),
            message.encode('utf-8'),
            hashlib.sha256
        ).digest()
        return base64.b64encode(signature).decode('utf-8')
    
    def get_headers(self, method, uri):
        """API ìš”ì²­ í—¤ë” ìƒì„±"""
        timestamp = str(int(time.time() * 1000))
        signature = self.generate_signature(timestamp, method, uri)
        
        return {
            'X-Timestamp': timestamp,
            'X-API-KEY': self.api_key,
            'X-Customer': str(self.customer_id),
            'X-Signature': signature,
            'Content-Type': 'application/json'
        }
    
    def search_keywords(self, hint_keywords, show_detail=1):
        """í‚¤ì›Œë“œ ë„êµ¬ APIë¥¼ ì‚¬ìš©í•œ ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰"""
        # ë„ì–´ì“°ê¸° í¬í•¨ í‚¤ì›Œë“œë¥¼ ì „ì²´ë¡œ ì²˜ë¦¬
        result = self._search_single_keyword(hint_keywords, show_detail)
        
        # ë„ì–´ì“°ê¸°ê°€ í¬í•¨ëœ í‚¤ì›Œë“œê°€ APIì—ì„œ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°, ì—°ê´€ê²€ìƒ‰ì–´ë¡œ ëŒ€ì²´
        if not result and ' ' in hint_keywords:
            print(f"âš ï¸ ë„ì–´ì“°ê¸° í¬í•¨ í‚¤ì›Œë“œ '{hint_keywords}'ê°€ APIì—ì„œ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            print("ğŸ”„ ì—°ê´€ê²€ìƒ‰ì–´ë¥¼ í™œìš©í•˜ì—¬ ëŒ€ì²´ í‚¤ì›Œë“œë¥¼ ì°¾ìŠµë‹ˆë‹¤...")
            
            # ì—°ê´€ê²€ìƒ‰ì–´ ì¶”ì¶œê¸°ë¡œ ëŒ€ì²´ í‚¤ì›Œë“œ ì°¾ê¸°
            related_extractor = NaverRelatedKeywordExtractor()
            related_keywords = related_extractor.extract_related_keywords(hint_keywords)
            
            # ì—°ê´€ê²€ìƒ‰ì–´ ì¤‘ì—ì„œ APIë¡œ ê²€ìƒ‰ ê°€ëŠ¥í•œ í‚¤ì›Œë“œ ì°¾ê¸°
            for related_keyword in related_keywords:
                if ' ' not in related_keyword:  # ë„ì–´ì“°ê¸°ê°€ ì—†ëŠ” í‚¤ì›Œë“œë§Œ ì‹œë„
                    print(f"ğŸ” ëŒ€ì²´ í‚¤ì›Œë“œë¡œ ì‹œë„: '{related_keyword}'")
                    result = self._search_single_keyword(related_keyword, show_detail)
                    if result and result.get('keywordList'):
                        print(f"âœ… ëŒ€ì²´ í‚¤ì›Œë“œ '{related_keyword}'ë¡œ ì„±ê³µ!")
                        break
        
        return result
    
    def _search_single_keyword(self, keyword, show_detail=1):
        """ë‹¨ì¼ í‚¤ì›Œë“œë¡œ API ê²€ìƒ‰"""
        uri = "/keywordstool"
        
        # ë„ì–´ì“°ê¸° ì œê±°í•˜ê³  ë¶™ì—¬ì„œ ì²˜ë¦¬
        if ' ' in keyword:
            # ë„ì–´ì“°ê¸° ì œê±°í•˜ê³  ë¶™ì—¬ì„œ ì²˜ë¦¬
            clean_keyword = keyword.replace(' ', '')
            print(f"[PROCESS] ë„ì–´ì“°ê¸° ì œê±°í•˜ì—¬ ì²˜ë¦¬: '{keyword}' -> '{clean_keyword}'")
            hint_keywords = clean_keyword
        else:
            hint_keywords = keyword
        
        # ë„¤ì´ë²„ ê²€ìƒ‰ API ì˜ˆì œ ë°©ì‹ìœ¼ë¡œ URL ì¸ì½”ë”©
        enc_keyword = urllib.parse.quote(hint_keywords)
        
        # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì„¤ì •
        params = {
            'hintKeywords': enc_keyword,
            'showDetail': show_detail
        }
        
        # URL ì¸ì½”ë”© - ë„¤ì´ë²„ API í‘œì¤€ ë°©ì‹ ì‚¬ìš©
        query_string = '&'.join([f"{k}={v}" for k, v in params.items()])
        full_uri = f"{uri}?{query_string}"
        
        headers = self.get_headers('GET', uri)
        url = f"{self.base_url}{full_uri}"
        
        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"API ìš”ì²­ ì˜¤ë¥˜: {e}")
            return None

def search_document_count(keyword):
    """
    ë„¤ì´ë²„ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œì˜ ë¸”ë¡œê·¸ ë¬¸ì„œìˆ˜ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        keyword (str): ê²€ìƒ‰í•  í‚¤ì›Œë“œ
        
    Returns:
        int: ë¸”ë¡œê·¸ ë¬¸ì„œ ìˆ˜ (ì‹¤íŒ¨ì‹œ 0)
    """
    import urllib.request
    import urllib.parse
    import json
    
    # í‚¤ì›Œë“œë¥¼ URL ì¸ì½”ë”© - ë„ì–´ì“°ê¸°ì™€ íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬ ê°œì„ 
    encText = urllib.parse.quote(keyword, safe='')
    
    # ë¸”ë¡œê·¸ ì¹´í…Œê³ ë¦¬ë§Œ ê²€ìƒ‰
    try:
        # ë„¤ì´ë²„ ê²€ìƒ‰ API URL (ë¸”ë¡œê·¸ ê²€ìƒ‰)
        url = f"https://openapi.naver.com/v1/search/blog?query=" + encText
        
        # ìš”ì²­ ê°ì²´ ìƒì„±
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
        request.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
        
        # API ìš”ì²­ ì‹¤í–‰
        response = urllib.request.urlopen(request)
        rescode = response.getcode()
        
        if rescode == 200:
            response_body = response.read()
            result = response_body.decode('utf-8')
            
            # JSON ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ì´ ë¬¸ì„œ ìˆ˜ ì¶”ì¶œ
            try:
                data = json.loads(result)
                blog_count = data.get('total', 0)
                return blog_count
            except json.JSONDecodeError:
                return 0
        else:
            return 0
            
    except Exception:
        return 0


def format_number(num_str):
    """ìˆ«ì ë¬¸ìì—´ì„ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    if num_str == "<10" or num_str == "0":
        return num_str
    
    try:
        num = int(num_str)
        if num >= 10000:
            return f"{num/10000:.1f}ë§Œ"
        elif num >= 1000:
            return f"{num/1000:.1f}ì²œ"
        else:
            return str(num)
    except:
        return num_str

def get_keyword_data(data, max_keywords=None):
    """í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
    if not data or 'keywordList' not in data:
        return []
    
    keywords = data['keywordList']
    if not keywords:
        return []
    
    # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
    if max_keywords:
        keywords = keywords[:max_keywords]
    
    keyword_data = []
    for i, keyword in enumerate(keywords):
        rel_keyword = keyword.get('relKeyword', '')
        
        # PC ê²€ìƒ‰ëŸ‰
        try:
            pc_count = int(keyword.get('monthlyPcQcCnt', '0')) if keyword.get('monthlyPcQcCnt', '0') != '<10' else 0
        except:
            pc_count = 0
        
        # ëª¨ë°”ì¼ ê²€ìƒ‰ëŸ‰
        try:
            mobile_count = int(keyword.get('monthlyMobileQcCnt', '0')) if keyword.get('monthlyMobileQcCnt', '0') != '<10' else 0
        except:
            mobile_count = 0
        
        # ì´ ê²€ìƒ‰ëŸ‰
        total_count = pc_count + mobile_count
        
        # ë¬¸ì„œìˆ˜ ê²€ìƒ‰ (ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì œí•œì ìœ¼ë¡œ)
        print(f"  [DOC] '{rel_keyword}' ë¬¸ì„œìˆ˜ ê²€ìƒ‰ ì¤‘...", end=" ")
        try:
            document_count = search_document_count(rel_keyword)
            if document_count is None:
                document_count = 0
            print(f"[OK] {document_count:,}ê°œ")
        except Exception as e:
            print(f"[ERROR] ì˜¤ë¥˜: {e}")
            document_count = 0
        
        # ê²½ìŸìœ¨ ê³„ì‚° (ë¬¸ì„œìˆ˜ / ì›”ê°„ì´ê²€ìƒ‰ëŸ‰)
        competition_ratio = 0
        if total_count > 0:
            competition_ratio = round(document_count / total_count, 2)
        
        keyword_data.append({
            'í‚¤ì›Œë“œ': rel_keyword,
            'PCê²€ìƒ‰ëŸ‰': pc_count,
            'ëª¨ë°”ì¼ê²€ìƒ‰ëŸ‰': mobile_count,
            'ì›”ê°„ì´ê²€ìƒ‰ëŸ‰': total_count,
            'ë¬¸ì„œìˆ˜': document_count,
            'ê²½ìŸìœ¨': competition_ratio
        })
        
        # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ (ë¹ ë¥¸ ì²˜ë¦¬)
        time.sleep(0.1)
    
    return keyword_data

def get_related_keywords_for_supplement(original_keywords, target_count, current_count):
    """
    í‚¤ì›Œë“œ ë¶€ì¡± ì‹œ ì—°ê´€ê²€ìƒ‰ì–´ë¡œ ë³´ì™„í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        original_keywords (list): ì›ë³¸ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        target_count (int): ëª©í‘œ í‚¤ì›Œë“œ ìˆ˜
        current_count (int): í˜„ì¬ ìˆ˜ì§‘ëœ í‚¤ì›Œë“œ ìˆ˜
        
    Returns:
        list: ì¶”ê°€ë¡œ ìˆ˜ì§‘í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    """
    needed_count = target_count - current_count
    if needed_count <= 0:
        return []
    
    print(f"\n[INFO] í‚¤ì›Œë“œ ë¶€ì¡±! {needed_count}ê°œ ë” í•„ìš”í•©ë‹ˆë‹¤.")
    print("[INFO] ì—°ê´€ê²€ìƒ‰ì–´ë¥¼ í™œìš©í•˜ì—¬ ì¶”ê°€ í‚¤ì›Œë“œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")
    
    related_extractor = NaverRelatedKeywordExtractor()
    additional_keywords = []
    
    # ì›ë³¸ í‚¤ì›Œë“œë“¤ë¡œë¶€í„° ì—°ê´€ê²€ìƒ‰ì–´ ìˆ˜ì§‘
    for keyword in original_keywords:
        if len(additional_keywords) >= needed_count:
            break
            
        print(f"\n[SEARCH] '{keyword}' ì—°ê´€ê²€ìƒ‰ì–´ ìˆ˜ì§‘ ì¤‘...")
        related_keywords = related_extractor.extract_related_keywords(keyword)
        
        # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ ì¶”ê°€
        for related_keyword in related_keywords:
            if related_keyword not in additional_keywords and len(additional_keywords) < needed_count:
                additional_keywords.append(related_keyword)
                print(f"  [ADD] ì¶”ê°€ í‚¤ì›Œë“œ: {related_keyword}")
        
        # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
        time.sleep(1)
    
    return additional_keywords[:needed_count]

def display_keyword_results(keyword_data, input_keywords):
    """í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
    if not keyword_data:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì…ë ¥í•œ í‚¤ì›Œë“œë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜ - ë„ì–´ì“°ê¸° ì²˜ë¦¬ ê°œì„ 
    input_list = [kw.strip() for kw in input_keywords.split(',') if kw.strip()]
    
    # í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰ëŸ‰ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_keywords = sorted(keyword_data, key=lambda x: x['ì›”ê°„ì´ê²€ìƒ‰ëŸ‰'], reverse=True)
    
    print(f"\nì…ë ¥í•œ í‚¤ì›Œë“œ: {', '.join(input_list)}")
    print(f"ì´ {len(keyword_data)}ê°œ í‚¤ì›Œë“œë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.\n")
    print("=" * 100)
    print(f"{'í‚¤ì›Œë“œ':<20} {'PCê²€ìƒ‰ëŸ‰':<12} {'ëª¨ë°”ì¼ê²€ìƒ‰ëŸ‰':<12} {'ì›”ê°„ì´ê²€ìƒ‰ëŸ‰':<12} {'ë¬¸ì„œìˆ˜':<12} {'ê²½ìŸìœ¨':<10}")
    print("=" * 100)
    
    for keyword in sorted_keywords:
        rel_keyword = keyword['í‚¤ì›Œë“œ']
        pc_qc = format_number(str(keyword['PCê²€ìƒ‰ëŸ‰']))
        mobile_qc = format_number(str(keyword['ëª¨ë°”ì¼ê²€ìƒ‰ëŸ‰']))
        total_qc = format_number(str(keyword['ì›”ê°„ì´ê²€ìƒ‰ëŸ‰']))
        doc_count = format_number(str(keyword['ë¬¸ì„œìˆ˜']))
        competition = keyword['ê²½ìŸìœ¨']
        
        # ì…ë ¥í•œ í‚¤ì›Œë“œì¸ì§€ í‘œì‹œ
        is_input = "â˜…" if rel_keyword.upper() in [kw.upper() for kw in input_list] else " "
        
        print(f"{is_input}{rel_keyword:<19} {pc_qc:<12} {mobile_qc:<12} {total_qc:<12} {doc_count:<12} {competition:<10}")
    
    print("=" * 100)
    print("â˜… í‘œì‹œ: ì…ë ¥í•˜ì‹  í‚¤ì›Œë“œ")

def save_to_excel(all_keyword_data, filename):
    """í‚¤ì›Œë“œ ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥"""
    if not all_keyword_data:
        print("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    if PANDAS_AVAILABLE:
        # pandasë¥¼ ì‚¬ìš©í•œ ì—‘ì…€ ì €ì¥
        try:
            # DataFrame ìƒì„±
            df = pd.DataFrame(all_keyword_data)
            
            # ì¤‘ë³µ ì œê±° (í‚¤ì›Œë“œ ê¸°ì¤€)
            df_unique = df.drop_duplicates(subset=['í‚¤ì›Œë“œ'], keep='first')
            
            # ê²€ìƒ‰ëŸ‰ ìˆœìœ¼ë¡œ ì •ë ¬
            df_sorted = df_unique.sort_values('ì›”ê°„ì´ê²€ìƒ‰ëŸ‰', ascending=False)
            
            # ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
            df_sorted.to_excel(filename, index=False, engine='openpyxl')
            print(f"\nê²°ê³¼ê°€ {filename} íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"ì´ {len(df_sorted)}ê°œì˜ ê³ ìœ  í‚¤ì›Œë“œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì—‘ì…€ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            # pandas ì‹¤íŒ¨ ì‹œ CSVë¡œ ëŒ€ì²´
            save_to_csv(all_keyword_data, filename.replace('.xlsx', '.csv'))
    else:
        # pandas ì—†ì´ CSVë¡œ ì €ì¥
        csv_filename = filename.replace('.xlsx', '.csv')
        save_to_csv(all_keyword_data, csv_filename)

def save_to_csv(all_keyword_data, filename):
    """í‚¤ì›Œë“œ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
    if not all_keyword_data:
        print("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì¤‘ë³µ ì œê±° (í‚¤ì›Œë“œ ê¸°ì¤€)
    unique_data = {}
    for data in all_keyword_data:
        keyword = data['í‚¤ì›Œë“œ']
        if keyword not in unique_data:
            unique_data[keyword] = data
    
    # ê²€ìƒ‰ëŸ‰ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_data = sorted(unique_data.values(), key=lambda x: x['ì›”ê°„ì´ê²€ìƒ‰ëŸ‰'], reverse=True)
    
    try:
        with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
            fieldnames = ['í‚¤ì›Œë“œ', 'PCê²€ìƒ‰ëŸ‰', 'ëª¨ë°”ì¼ê²€ìƒ‰ëŸ‰', 'ì›”ê°„ì´ê²€ìƒ‰ëŸ‰', 'ë¬¸ì„œìˆ˜', 'ê²½ìŸìœ¨']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for data in sorted_data:
                writer.writerow(data)
        
        print(f"\nê²°ê³¼ê°€ {filename} íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ì´ {len(sorted_data)}ê°œì˜ ê³ ìœ  í‚¤ì›Œë“œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"CSV íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # API ì¸ì¦ ì •ë³´
    API_KEY = "01000000005d84e573bf51b1af97bd55d80b4d161478ae089b8b686db032a1b9d3addb3ad3"
    SECRET_KEY = "AQAAAABdhOVzv1Gxr5e9VdgLTRYUk3Gl94kmw7v5tmIXJb3Rrg=="
    CUSTOMER_ID = 3495013
    
    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    print("=" * 60)
    print("ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API + ì—°ê´€ê²€ìƒ‰ì–´ í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ ì¡°íšŒ ë° ë¸”ë¡œê·¸ ì œëª© ì¶”ì²œ ë„êµ¬")
    print("=" * 60)
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    if len(sys.argv) >= 2:
        hint_keywords = sys.argv[1]
    else:
        print("\nê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        print("ì˜ˆì‹œ: ê½ƒë°°ë‹¬, flower, ê½ƒë°°ë‹¬,flower,í™”í™˜")
        hint_keywords = input("í‚¤ì›Œë“œ: ").strip()
        
        if not hint_keywords:
            print("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            sys.exit(1)
    
    # ì¡°íšŒí•  í‚¤ì›Œë“œ ê°œìˆ˜ ì…ë ¥ (ëª…ë ¹í–‰ ì¸ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’)
    if len(sys.argv) >= 3:
        try:
            max_keywords = int(sys.argv[2])
        except ValueError:
            max_keywords = 20
    else:
        try:
            max_keywords = int(input(f"\nëª‡ ê°œì˜ í‚¤ì›Œë“œë¥¼ ì¡°íšŒí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ê¸°ë³¸ê°’: 20): ") or "20")
        except (ValueError, EOFError):
            max_keywords = 20
    
    print(f"\ní‚¤ì›Œë“œ ê²€ìƒ‰ ì¤‘: {hint_keywords}")
    print(f"ìµœëŒ€ {max_keywords}ê°œì˜ í‚¤ì›Œë“œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
    print("ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ í‚¤ì›Œë“œì™€ ê²€ìƒ‰ëŸ‰ì„ ì¡°íšŒí•©ë‹ˆë‹¤...")
    print("í‚¤ì›Œë“œê°€ ë¶€ì¡±í•  ê²½ìš° ì—°ê´€ê²€ìƒ‰ì–´ë¥¼ í™œìš©í•˜ì—¬ ë³´ì™„í•©ë‹ˆë‹¤...\n")
    
    # API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    api = NaverSearchAdAPI(API_KEY, SECRET_KEY, CUSTOMER_ID)
    
    # ëª¨ë“  í‚¤ì›Œë“œ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    all_keyword_data = []
    searched_keywords = set()  # ì´ë¯¸ ê²€ìƒ‰í•œ í‚¤ì›Œë“œ ì¶”ì 
    initial_keywords = [kw.strip() for kw in hint_keywords.split(',') if kw.strip()]  # ì´ˆê¸° í‚¤ì›Œë“œë“¤ - ë„ì–´ì“°ê¸° ì²˜ë¦¬ ê°œì„ 
    
    # 1ë‹¨ê³„: ì´ˆê¸° í‚¤ì›Œë“œë“¤ë¡œ ê²€ìƒ‰
    print("=" * 60)
    print("1ë‹¨ê³„: ì´ˆê¸° í‚¤ì›Œë“œ ê²€ìƒ‰")
    print("=" * 60)
    
    for i, current_keyword in enumerate(initial_keywords):
        # ëª©í‘œ ê°œìˆ˜ì— ë„ë‹¬í–ˆìœ¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ
        if len(all_keyword_data) >= max_keywords:
            print(f"\n[TARGET] ëª©í‘œ í‚¤ì›Œë“œ ê°œìˆ˜ {max_keywords}ê°œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤!")
            break
            
        if current_keyword in searched_keywords:
            print(f"ì´ë¯¸ ê²€ìƒ‰í•œ í‚¤ì›Œë“œ '{current_keyword}' ê±´ë„ˆë›°ê¸°")
            continue
        
        print(f"\n[{i+1}íšŒì°¨] í‚¤ì›Œë“œ ê²€ìƒ‰: {current_keyword}")
        searched_keywords.add(current_keyword)
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤í–‰
        result = api.search_keywords(current_keyword, show_detail=1)
        
        if result:
            # ë‚¨ì€ ìŠ¬ë¡¯ ê³„ì‚°
            remaining_slots = max_keywords - len(all_keyword_data)
            
            # ë‚¨ì€ ìŠ¬ë¡¯ë§Œí¼ë§Œ ì²˜ë¦¬
            keyword_data = get_keyword_data(result, remaining_slots)
            
            if keyword_data:
                all_keyword_data.extend(keyword_data)
                
                # í˜„ì¬ ê²°ê³¼ í‘œì‹œ
                display_keyword_results(keyword_data, current_keyword)
                
                print(f"í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ í‚¤ì›Œë“œ: {len(all_keyword_data)}ê°œ")
                
                # ëª©í‘œ ê°œìˆ˜ì— ë„ë‹¬í–ˆìœ¼ë©´ ì¢…ë£Œ
                if len(all_keyword_data) >= max_keywords:
                    print(f"\n[TARGET] ëª©í‘œ í‚¤ì›Œë“œ ê°œìˆ˜ {max_keywords}ê°œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤!")
                    break
            else:
                print(f"'{current_keyword}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print(f"'{current_keyword}' ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
        time.sleep(0.5)
    
    # 2ë‹¨ê³„: í‚¤ì›Œë“œê°€ ë¶€ì¡±í•œ ê²½ìš° ì—°ê´€ê²€ìƒ‰ì–´ë¡œ ë³´ì™„
    if len(all_keyword_data) < max_keywords:
        print("\n" + "=" * 60)
        print("2ë‹¨ê³„: ì—°ê´€ê²€ìƒ‰ì–´ë¡œ í‚¤ì›Œë“œ ë³´ì™„")
        print("=" * 60)
        
        # ì—°ê´€ê²€ìƒ‰ì–´ë¡œ ì¶”ê°€ í‚¤ì›Œë“œ ìˆ˜ì§‘
        additional_keywords = get_related_keywords_for_supplement(
            initial_keywords, max_keywords, len(all_keyword_data)
        )
        
        # ì¶”ê°€ í‚¤ì›Œë“œë“¤ë¡œ ê²€ìƒ‰
        for additional_keyword in additional_keywords:
            if len(all_keyword_data) >= max_keywords:
                break
                
            if additional_keyword in searched_keywords:
                continue
                
            print(f"\n[SEARCH] ì¶”ê°€ í‚¤ì›Œë“œ ê²€ìƒ‰: {additional_keyword}")
            searched_keywords.add(additional_keyword)
            
            # í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤í–‰
            result = api.search_keywords(additional_keyword, show_detail=1)
            
            if result:
                # ë‚¨ì€ ìŠ¬ë¡¯ ê³„ì‚°
                remaining_slots = max_keywords - len(all_keyword_data)
                
                # ë‚¨ì€ ìŠ¬ë¡¯ë§Œí¼ë§Œ ì²˜ë¦¬
                keyword_data = get_keyword_data(result, remaining_slots)
                
                if keyword_data:
                    all_keyword_data.extend(keyword_data)
                    print(f"í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ í‚¤ì›Œë“œ: {len(all_keyword_data)}ê°œ")
                    
                    # ëª©í‘œ ê°œìˆ˜ì— ë„ë‹¬í–ˆìœ¼ë©´ ì¢…ë£Œ
                    if len(all_keyword_data) >= max_keywords:
                        print(f"\n[TARGET] ëª©í‘œ í‚¤ì›Œë“œ ê°œìˆ˜ {max_keywords}ê°œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤!")
                        break
                else:
                    print(f"'{additional_keyword}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                print(f"'{additional_keyword}' ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            
            # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
            time.sleep(0.5)
    
    # ìµœì¢… ê²°ê³¼ ì €ì¥
    if all_keyword_data:
        # íŒŒì¼ëª… ìƒì„± (ê²€ìƒ‰í•œë‚ ì§œ_ì…ë ¥í•œí‚¤ì›Œë“œ.xlsx í˜•ì‹)
        import re
        from datetime import datetime
        
        # í˜„ì¬ ë‚ ì§œë¥¼ YYYYMMDD í˜•ì‹ìœ¼ë¡œ ìƒì„±
        current_date = datetime.now().strftime("%Y%m%d")
        
        # ì…ë ¥ í‚¤ì›Œë“œì—ì„œ ì²« ë²ˆì§¸ í‚¤ì›Œë“œë§Œ ì‚¬ìš© (ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê²½ìš°)
        first_keyword = hint_keywords.split(',')[0].strip()
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì •ë¦¬
        clean_keyword = re.sub(r'[^\w\s-]', '', first_keyword)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
        clean_keyword = re.sub(r'[-\s]+', '', clean_keyword)  # ë„ì–´ì“°ê¸°ì™€ í•˜ì´í”ˆ ì œê±°
        
        filename = f"{current_date}_{clean_keyword}.xlsx"
        
        print(f"\n{'='*60}")
        print("[SAVE] ìµœì¢… ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ ì¤‘...")
        save_to_excel(all_keyword_data, filename)
        
        # ìµœì¢… í†µê³„
        print(f"\n{'='*60}")
        print("[SUCCESS] ê²€ìƒ‰ ì™„ë£Œ!")
        print(f"[STAT] ì´ ê²€ìƒ‰í•œ í‚¤ì›Œë“œ: {len(searched_keywords)}ê°œ")
        print(f"[STAT] ì´ ìˆ˜ì§‘ëœ ë°ì´í„°: {len(all_keyword_data)}ê°œ")
        print(f"[FILE] ì €ì¥ëœ íŒŒì¼: {filename}")
        print(f"[PATH] íŒŒì¼ ìœ„ì¹˜: {os.path.abspath(filename)}")
        print("[INFO] ì—°ê´€ê²€ìƒ‰ì–´ë¥¼ í™œìš©í•˜ì—¬ ëª©í‘œ í‚¤ì›Œë“œ ìˆ˜ë¥¼ ë‹¬ì„±í–ˆìŠµë‹ˆë‹¤!")
    else:
        print("[ERROR] ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()

