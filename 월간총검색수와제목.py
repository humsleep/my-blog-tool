#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  APIë¥¼ ì‚¬ìš©í•œ í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ ì¡°íšŒ ë° ë¸”ë¡œê·¸ ì œëª© ì¶”ì²œ ë„êµ¬
ì›”ê°„ì´ê²€ìƒ‰ìˆ˜ì™€ì œëª©.py

ì‚¬ìš©ë²•:
    python ì›”ê°„ì´ê²€ìƒ‰ìˆ˜ì™€ì œëª©.py "ê²€ìƒ‰í•  í‚¤ì›Œë“œ"
    python ì›”ê°„ì´ê²€ìƒ‰ìˆ˜ì™€ì œëª©.py "ê½ƒë°°ë‹¬,flower,í™”í™˜"
"""

import hashlib
import hmac
import base64
import time
import requests
import json
import sys
from urllib.parse import quote
from datetime import datetime
import os
import csv
import random

# pandasê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ëŒ€ì²´ í•¨ìˆ˜ë“¤
try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError:
    PANDAS_AVAILABLE = False
    print("pandasê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.")

# ë„¤ì´ë²„ ê²€ìƒ‰ API í´ë¼ì´ì–¸íŠ¸ ì •ë³´ (ë¬¸ì„œìˆ˜ ê²€ìƒ‰ìš©)
NAVER_CLIENT_ID = "tth9fnsKBgcMDWVf96EV"
NAVER_CLIENT_SECRET = "tgW9pUVIRc"

class NaverSearchAdAPI:
    """ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, api_key, secret_key, customer_id):
        self.api_key = api_key
        self.secret_key = secret_key
        self.customer_id = customer_id
        self.base_url = "https://api.searchad.naver.com"
        
    def generate_signature(self, timestamp, method, uri):
        """HMAC-SHA256 ì„œëª… ìƒì„±"""
        message = f"{timestamp}.{method}.{uri}"
        signature = hmac.new(
            self.secret_key.encode('utf-8'),
            message.encode('utf-8'),
            hashlib.sha256
        ).digest()
        return base64.b64encode(signature).decode('utf-8')
    
    def get_headers(self, method, uri):
        """API ìš”ì²­ í—¤ë” ìƒì„±"""
        timestamp = str(int(time.time() * 1000))
        signature = self.generate_signature(timestamp, method, uri)
        
        return {
            'X-Timestamp': timestamp,
            'X-API-KEY': self.api_key,
            'X-Customer': str(self.customer_id),
            'X-Signature': signature,
            'Content-Type': 'application/json'
        }
    
    def search_keywords(self, hint_keywords, show_detail=1):
        """í‚¤ì›Œë“œ ë„êµ¬ APIë¥¼ ì‚¬ìš©í•œ ê´€ë ¨ í‚¤ì›Œë“œ ê²€ìƒ‰"""
        uri = "/keywordstool"
        
        # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì„¤ì •
        params = {
            'hintKeywords': hint_keywords,
            'showDetail': show_detail
        }
        
        # URL ì¸ì½”ë”©
        query_string = '&'.join([f"{k}={quote(str(v))}" for k, v in params.items()])
        full_uri = f"{uri}?{query_string}"
        
        headers = self.get_headers('GET', uri)
        url = f"{self.base_url}{full_uri}"
        
        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"API ìš”ì²­ ì˜¤ë¥˜: {e}")
            return None

def search_document_count(keyword):
    """
    ë„¤ì´ë²„ ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œì˜ ë¸”ë¡œê·¸ ë¬¸ì„œìˆ˜ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        keyword (str): ê²€ìƒ‰í•  í‚¤ì›Œë“œ
        
    Returns:
        int: ë¸”ë¡œê·¸ ë¬¸ì„œ ìˆ˜ (ì‹¤íŒ¨ì‹œ 0)
    """
    import urllib.request
    import urllib.parse
    import json
    
    # í‚¤ì›Œë“œë¥¼ URL ì¸ì½”ë”©
    encText = urllib.parse.quote(keyword)
    
    # ë¸”ë¡œê·¸ ì¹´í…Œê³ ë¦¬ë§Œ ê²€ìƒ‰
    try:
        # ë„¤ì´ë²„ ê²€ìƒ‰ API URL (ë¸”ë¡œê·¸ ê²€ìƒ‰)
        url = f"https://openapi.naver.com/v1/search/blog?query=" + encText
        
        # ìš”ì²­ ê°ì²´ ìƒì„±
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
        request.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
        
        # API ìš”ì²­ ì‹¤í–‰
        response = urllib.request.urlopen(request)
        rescode = response.getcode()
        
        if rescode == 200:
            response_body = response.read()
            result = response_body.decode('utf-8')
            
            # JSON ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ì´ ë¬¸ì„œ ìˆ˜ ì¶”ì¶œ
            try:
                data = json.loads(result)
                blog_count = data.get('total', 0)
                return blog_count
            except json.JSONDecodeError:
                return 0
        else:
            return 0
            
    except Exception:
        return 0

def generate_blog_titles(keyword, search_volume, competition_ratio):
    """
    í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ë„¤ì´ë²„ ë¸”ë¡œê·¸ì— ì í•©í•œ ì œëª© 5ê°œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        keyword (str): í‚¤ì›Œë“œ
        search_volume (int): ì›”ê°„ ê²€ìƒ‰ëŸ‰
        competition_ratio (float): ê²½ìŸìœ¨
        
    Returns:
        list: ì œëª© 5ê°œ ë¦¬ìŠ¤íŠ¸
    """
    
    # 2024ë…„ ìµœì‹  íŠ¸ë Œë“œì— ë§ëŠ” ì œëª© í…œí”Œë¦¿ë“¤
    title_templates = [
        # í˜¸ê¸°ì‹¬ ìœ ë°œí˜•
        f"ğŸ”¥ {keyword} ì™„ë²½ ê°€ì´ë“œ - ì´ê±° í•˜ë‚˜ë©´ ë!",
        f"âœ¨ {keyword} ë¹„ë°€ ê³µê°œ - 99%ê°€ ëª¨ë¥´ëŠ” ì§„ì‹¤",
        f"ğŸ’¡ {keyword} ê¿€íŒ - ì „ë¬¸ê°€ë„ ë†€ë€ ë…¸í•˜ìš°",
        f"ğŸ¯ {keyword} ì™„ì „ì •ë³µ - ì´ˆë³´ìë„ OK!",
        f"ğŸš€ {keyword} ë§ˆìŠ¤í„°í•˜ê¸° - ë‹¨ê³„ë³„ ê°€ì´ë“œ",
        
        # ìˆ«ì í™œìš©í˜•
        f"ğŸ“Š {keyword} TOP 10 - 2024ë…„ ìµœì‹  ìˆœìœ„",
        f"ğŸª {keyword} 5ê°€ì§€ ë°©ë²• - ì‹¤íŒ¨ ì—†ëŠ” ì„ íƒ",
        f"ğŸ“ˆ {keyword} 3ë‹¨ê³„ ì™„ì„± - ëˆ„êµ¬ë‚˜ ë”°ë¼í•˜ê¸°",
        f"ğŸ¨ {keyword} 7ê°€ì§€ ìŠ¤íƒ€ì¼ - ì·¨í–¥ë³„ ì¶”ì²œ",
        f"âš¡ {keyword} 1ë¶„ ì™„ì„± - ì´ˆê°„ë‹¨ ë°©ë²•",
        
        # ê°ì • ì–´í•„í˜•
        f"ğŸ˜ {keyword} ì™„ì „ ë§Œì¡± - í›„ê¸° ëª¨ìŒì§‘",
        f"ğŸ¤© {keyword} ëŒ€ë°• í›„ê¸° - ì‹¤ì œ ê²½í—˜ë‹´",
        f"ğŸ˜Š {keyword} í–‰ë³µí•œ ì„ íƒ - ë§Œì¡±ë„ 100%",
        f"ğŸ¥° {keyword} ì¶”ì²œ ì´ìœ  - ì™œ ì´ê±¸ ì„ íƒí–ˆì„ê¹Œ?",
        f"ğŸ˜ {keyword} ê³ ìˆ˜ ë˜ê¸° - í”„ë¡œì˜ ë¹„ë°€",
        
        # ë¹„êµ/ëŒ€ì¡°í˜•
        f"âš–ï¸ {keyword} vs ëŒ€ì•ˆ - ì–´ë–¤ ê²Œ ë” ì¢‹ì„ê¹Œ?",
        f"ğŸ”„ {keyword} ì „í›„ ë¹„êµ - ë†€ë¼ìš´ ë³€í™”",
        f"ğŸ“Š {keyword} ì¥ë‹¨ì  ë¶„ì„ - ì†”ì§í•œ ë¦¬ë·°",
        f"ğŸ¯ {keyword} ì„ íƒ ê¸°ì¤€ - ì´ê²ƒë§Œ ì•Œë©´ OK",
        f"ğŸ’¯ {keyword} ì™„ë²½ ë¹„êµ - ìµœì¢… ì„ íƒ ê°€ì´ë“œ",
        
        # ì‹œê°„/ì‹œê¸° í™œìš©í˜•
        f"â° {keyword} ì§€ê¸ˆì´ ê¸°íšŒ - íƒ€ì´ë° ì™„ë²½",
        f"ğŸ“… {keyword} 2024ë…„ íŠ¸ë Œë“œ - ì˜¬í•´ í•«í•œ ì„ íƒ",
        f"ğŸŒŸ {keyword} ì‹œì¦Œë³„ ê°€ì´ë“œ - ì–¸ì œê°€ ìµœê³ ?",
        f"ğŸŠ {keyword} íŠ¹ë³„í•œ ìˆœê°„ - ê¸°ì–µì— ë‚¨ëŠ” ì„ íƒ",
        f"â³ {keyword} ë§ˆì§€ë§‰ ê¸°íšŒ - ë†“ì¹˜ë©´ í›„íšŒ",
        
        # ë¬¸ì œ í•´ê²°í˜•
        f"â“ {keyword} ê³ ë¯¼ í•´ê²° - ì´ì œ ë!",
        f"ğŸ”§ {keyword} ë¬¸ì œ í•´ê²° - 100% í•´ê²°ë²•",
        f"ğŸ’Š {keyword} ê³ ë¯¼ ì™„ì¹˜ - ë” ì´ìƒ ê³ ë¯¼ NO",
        f"ğŸ¯ {keyword} ì™„ë²½ ì†”ë£¨ì…˜ - ì›ìƒ· í•´ê²°",
        f"âš¡ {keyword} ì¦‰ì‹œ í•´ê²° - ë‹¹ì¥ ì ìš© ê°€ëŠ¥",
        
        # í˜œíƒ/ì´ì  ê°•ì¡°í˜•
        f"ğŸ {keyword} íŠ¹ë³„ í˜œíƒ - ì§€ê¸ˆë§Œ ê¸°íšŒ",
        f"ğŸ’° {keyword} ë¹„ìš© ì ˆì•½ - ëˆ ë²„ëŠ” ë°©ë²•",
        f"â±ï¸ {keyword} ì‹œê°„ ì ˆì•½ - íš¨ìœ¨ì„± ê·¹ëŒ€í™”",
        f"ğŸ¯ {keyword} ì„±ê³µ ë³´ì¥ - ì‹¤íŒ¨ ì—†ëŠ” ë°©ë²•",
        f"ğŸ† {keyword} ìµœê³ ì˜ ì„ íƒ - 1ë“±ì˜ ë¹„ë°€",
        
        # ê°œì¸í™”/ê²½í—˜í˜•
        f"ğŸ‘¤ {keyword} ë‚˜ë§Œì˜ ìŠ¤íƒ€ì¼ - ê°œì„± ìˆëŠ” ì„ íƒ",
        f"ğŸ¨ {keyword} DIY ê°€ì´ë“œ - ì§ì ‘ ë§Œë“¤ì–´ë³´ê¸°",
        f"ğŸ“ {keyword} ì²´í—˜ í›„ê¸° - ì†”ì§í•œ ì´ì•¼ê¸°",
        f"ğŸª {keyword} ë‚˜ì˜ ê²½í—˜ - ì‹¤ì œ ì‚¬ìš©ê¸°",
        f"ğŸ’­ {keyword} ì†”ì§ í›„ê¸° - ì¢‹ì€ ì ê³¼ ì•„ì‰¬ìš´ ì ",
        
        # ê¸´ê¸‰ì„±/í•œì •ì„±
        f"ğŸš¨ {keyword} ê¸´ê¸‰ ê³µì§€ - ë†“ì¹˜ë©´ ì•ˆ ë˜ëŠ” ì •ë³´",
        f"â° {keyword} ë§ˆê° ì„ë°• - ì„œë‘˜ëŸ¬ì•¼ í•  ì´ìœ ",
        f"ğŸ¯ {keyword} í•œì • ê¸°íšŒ - ì§€ê¸ˆë§Œ íŠ¹ê°€",
        f"ğŸ”¥ {keyword} í•«í•œ ì´ìŠˆ - í™”ì œì˜ ì¤‘ì‹¬",
        f"â­ {keyword} ë² ìŠ¤íŠ¸ì…€ëŸ¬ - ì¸ê¸° 1ìœ„",
        
        # ì „ë¬¸ì„± ì–´í•„í˜•
        f"ğŸ‘¨â€ğŸ’¼ {keyword} ì „ë¬¸ê°€ ë¶„ì„ - ê¹Šì´ ìˆëŠ” ë¦¬ë·°",
        f"ğŸ”¬ {keyword} ê³¼í•™ì  ì ‘ê·¼ - ë°ì´í„°ë¡œ ì¦ëª…",
        f"ğŸ“š {keyword} ì™„ì „ ë¶„ì„ - ëª¨ë“  ê²ƒ ì •ë¦¬",
        f"ğŸ“ {keyword} ë§ˆìŠ¤í„° í´ë˜ìŠ¤ - ì „ë¬¸ê°€ì˜ ë…¸í•˜ìš°",
        f"ğŸ… {keyword} ì¸ì¦ ì™„ë£Œ - ê²€ì¦ëœ ë°©ë²•"
    ]
    
    # ê²€ìƒ‰ëŸ‰ê³¼ ê²½ìŸìœ¨ì— ë”°ë¥¸ ì œëª© ì„ íƒ ë¡œì§
    selected_titles = []
    
    # ê²€ìƒ‰ëŸ‰ì´ ë†’ìœ¼ë©´ ì¸ê¸°/íŠ¸ë Œë“œ ê´€ë ¨ ì œëª© ìš°ì„ 
    if search_volume > 10000:
        popular_templates = [t for t in title_templates if any(word in t for word in ['ğŸ”¥', 'â­', 'ğŸ“ˆ', 'ğŸ¯', 'ğŸš€'])]
        selected_titles.extend(random.sample(popular_templates, 2))
    
    # ê²½ìŸìœ¨ì´ ë‚®ìœ¼ë©´ í˜¸ê¸°ì‹¬/ë¹„ë°€ ê´€ë ¨ ì œëª© ìš°ì„ 
    if competition_ratio < 0.5:
        curiosity_templates = [t for t in title_templates if any(word in t for word in ['âœ¨', 'ğŸ’¡', 'ë¹„ë°€', 'ì™„ë²½', 'ê¿€íŒ'])]
        selected_titles.extend(random.sample(curiosity_templates, 2))
    
    # ë‚˜ë¨¸ì§€ëŠ” ëœë¤ ì„ íƒ
    remaining_templates = [t for t in title_templates if t not in selected_titles]
    selected_titles.extend(random.sample(remaining_templates, 5 - len(selected_titles)))
    
    # ì¤‘ë³µ ì œê±° ë° 5ê°œë¡œ ì œí•œ
    unique_titles = list(dict.fromkeys(selected_titles))[:5]
    
    # 5ê°œê°€ ì•ˆ ë˜ë©´ ì¶”ê°€ë¡œ ëœë¤ ì„ íƒ
    while len(unique_titles) < 5:
        additional_template = random.choice(title_templates)
        if additional_template not in unique_titles:
            unique_titles.append(additional_template)
    
    return unique_titles[:5]

def format_number(num_str):
    """ìˆ«ì ë¬¸ìì—´ì„ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·íŒ…"""
    if num_str == "<10" or num_str == "0":
        return num_str
    
    try:
        num = int(num_str)
        if num >= 10000:
            return f"{num/10000:.1f}ë§Œ"
        elif num >= 1000:
            return f"{num/1000:.1f}ì²œ"
        else:
            return str(num)
    except:
        return num_str

def get_keyword_data(data, max_keywords=None):
    """í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë°ì´í„° ì¶”ì¶œ"""
    if not data or 'keywordList' not in data:
        return []
    
    keywords = data['keywordList']
    if not keywords:
        return []
    
    # ìµœëŒ€ ê°œìˆ˜ ì œí•œ
    if max_keywords:
        keywords = keywords[:max_keywords]
    
    keyword_data = []
    for i, keyword in enumerate(keywords):
        rel_keyword = keyword.get('relKeyword', '')
        
        # PC ê²€ìƒ‰ëŸ‰
        try:
            pc_count = int(keyword.get('monthlyPcQcCnt', '0')) if keyword.get('monthlyPcQcCnt', '0') != '<10' else 0
        except:
            pc_count = 0
        
        # ëª¨ë°”ì¼ ê²€ìƒ‰ëŸ‰
        try:
            mobile_count = int(keyword.get('monthlyMobileQcCnt', '0')) if keyword.get('monthlyMobileQcCnt', '0') != '<10' else 0
        except:
            mobile_count = 0
        
        # ì´ ê²€ìƒ‰ëŸ‰
        total_count = pc_count + mobile_count
        
        # ë¬¸ì„œìˆ˜ ê²€ìƒ‰ (ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•´ ì œí•œì ìœ¼ë¡œ)
        print(f"  ğŸ“„ '{rel_keyword}' ë¬¸ì„œìˆ˜ ê²€ìƒ‰ ì¤‘...", end=" ")
        try:
            document_count = search_document_count(rel_keyword)
            if document_count is None:
                document_count = 0
            print(f"âœ… {document_count:,}ê°œ")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
            document_count = 0
        
        # ê²½ìŸìœ¨ ê³„ì‚° (ë¬¸ì„œìˆ˜ / ì›”ê°„ì´ê²€ìƒ‰ëŸ‰)
        competition_ratio = 0
        if total_count > 0:
            competition_ratio = round(document_count / total_count, 2)
        
        # ë¸”ë¡œê·¸ ì œëª© ì¶”ì²œ ìƒì„±
        print(f"  ğŸ“ '{rel_keyword}' ì œëª© ì¶”ì²œ ìƒì„± ì¤‘...", end=" ")
        try:
            blog_titles = generate_blog_titles(rel_keyword, total_count, competition_ratio)
            print(f"âœ… {len(blog_titles)}ê°œ")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}")
            blog_titles = [f"{rel_keyword} ê´€ë ¨ ì •ë³´", f"{rel_keyword} ì™„ë²½ ê°€ì´ë“œ", f"{rel_keyword} ì¶”ì²œ", f"{rel_keyword} í›„ê¸°", f"{rel_keyword} ë¦¬ë·°"]
        
        keyword_data.append({
            'í‚¤ì›Œë“œ': rel_keyword,
            'PCê²€ìƒ‰ëŸ‰': pc_count,
            'ëª¨ë°”ì¼ê²€ìƒ‰ëŸ‰': mobile_count,
            'ì›”ê°„ì´ê²€ìƒ‰ëŸ‰': total_count,
            'ë¬¸ì„œìˆ˜': document_count,
            'ê²½ìŸìœ¨': competition_ratio,
            'ì¶”ì²œì œëª©1': blog_titles[0] if len(blog_titles) > 0 else '',
            'ì¶”ì²œì œëª©2': blog_titles[1] if len(blog_titles) > 1 else '',
            'ì¶”ì²œì œëª©3': blog_titles[2] if len(blog_titles) > 2 else '',
            'ì¶”ì²œì œëª©4': blog_titles[3] if len(blog_titles) > 3 else '',
            'ì¶”ì²œì œëª©5': blog_titles[4] if len(blog_titles) > 4 else ''
        })
        
        # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ (ë¹ ë¥¸ ì²˜ë¦¬)
        time.sleep(0.1)
    
    return keyword_data

def display_keyword_results(keyword_data, input_keywords):
    """í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥"""
    if not keyword_data:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì…ë ¥í•œ í‚¤ì›Œë“œë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    input_list = [kw.strip() for kw in input_keywords.split(',')]
    
    # í‚¤ì›Œë“œë¥¼ ê²€ìƒ‰ëŸ‰ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_keywords = sorted(keyword_data, key=lambda x: x['ì›”ê°„ì´ê²€ìƒ‰ëŸ‰'], reverse=True)
    
    print(f"\nì…ë ¥í•œ í‚¤ì›Œë“œ: {', '.join(input_list)}")
    print(f"ì´ {len(keyword_data)}ê°œ í‚¤ì›Œë“œë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.\n")
    print("=" * 150)
    print(f"{'í‚¤ì›Œë“œ':<20} {'PCê²€ìƒ‰ëŸ‰':<12} {'ëª¨ë°”ì¼ê²€ìƒ‰ëŸ‰':<12} {'ì›”ê°„ì´ê²€ìƒ‰ëŸ‰':<12} {'ë¬¸ì„œìˆ˜':<12} {'ê²½ìŸìœ¨':<10} {'ì¶”ì²œì œëª©':<60}")
    print("=" * 150)
    
    for keyword in sorted_keywords:
        rel_keyword = keyword['í‚¤ì›Œë“œ']
        pc_qc = format_number(str(keyword['PCê²€ìƒ‰ëŸ‰']))
        mobile_qc = format_number(str(keyword['ëª¨ë°”ì¼ê²€ìƒ‰ëŸ‰']))
        total_qc = format_number(str(keyword['ì›”ê°„ì´ê²€ìƒ‰ëŸ‰']))
        doc_count = format_number(str(keyword['ë¬¸ì„œìˆ˜']))
        competition = keyword['ê²½ìŸìœ¨']
        
        # ì²« ë²ˆì§¸ ì¶”ì²œ ì œëª©ë§Œ í‘œì‹œ (ê³µê°„ ì ˆì•½)
        first_title = keyword['ì¶”ì²œì œëª©1'][:55] + "..." if len(keyword['ì¶”ì²œì œëª©1']) > 55 else keyword['ì¶”ì²œì œëª©1']
        
        # ì…ë ¥í•œ í‚¤ì›Œë“œì¸ì§€ í‘œì‹œ
        is_input = "â˜…" if rel_keyword.upper() in [kw.upper() for kw in input_list] else " "
        
        print(f"{is_input}{rel_keyword:<19} {pc_qc:<12} {mobile_qc:<12} {total_qc:<12} {doc_count:<12} {competition:<10} {first_title:<60}")
    
    print("=" * 150)
    print("â˜… í‘œì‹œ: ì…ë ¥í•˜ì‹  í‚¤ì›Œë“œ")
    print("\nğŸ“ ì „ì²´ ì¶”ì²œ ì œëª©ì„ ë³´ë ¤ë©´ ì—‘ì…€ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”!")

def save_to_excel(all_keyword_data, filename):
    """í‚¤ì›Œë“œ ë°ì´í„°ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥"""
    if not all_keyword_data:
        print("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    if PANDAS_AVAILABLE:
        # pandasë¥¼ ì‚¬ìš©í•œ ì—‘ì…€ ì €ì¥
        try:
            # DataFrame ìƒì„±
            df = pd.DataFrame(all_keyword_data)
            
            # ì¤‘ë³µ ì œê±° (í‚¤ì›Œë“œ ê¸°ì¤€)
            df_unique = df.drop_duplicates(subset=['í‚¤ì›Œë“œ'], keep='first')
            
            # ê²€ìƒ‰ëŸ‰ ìˆœìœ¼ë¡œ ì •ë ¬
            df_sorted = df_unique.sort_values('ì›”ê°„ì´ê²€ìƒ‰ëŸ‰', ascending=False)
            
            # ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥
            df_sorted.to_excel(filename, index=False, engine='openpyxl')
            print(f"\nê²°ê³¼ê°€ {filename} íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"ì´ {len(df_sorted)}ê°œì˜ ê³ ìœ  í‚¤ì›Œë“œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì—‘ì…€ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            # pandas ì‹¤íŒ¨ ì‹œ CSVë¡œ ëŒ€ì²´
            save_to_csv(all_keyword_data, filename.replace('.xlsx', '.csv'))
    else:
        # pandas ì—†ì´ CSVë¡œ ì €ì¥
        csv_filename = filename.replace('.xlsx', '.csv')
        save_to_csv(all_keyword_data, csv_filename)

def save_to_csv(all_keyword_data, filename):
    """í‚¤ì›Œë“œ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
    if not all_keyword_data:
        print("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì¤‘ë³µ ì œê±° (í‚¤ì›Œë“œ ê¸°ì¤€)
    unique_data = {}
    for data in all_keyword_data:
        keyword = data['í‚¤ì›Œë“œ']
        if keyword not in unique_data:
            unique_data[keyword] = data
    
    # ê²€ìƒ‰ëŸ‰ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_data = sorted(unique_data.values(), key=lambda x: x['ì›”ê°„ì´ê²€ìƒ‰ëŸ‰'], reverse=True)
    
    try:
        with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
            fieldnames = ['í‚¤ì›Œë“œ', 'PCê²€ìƒ‰ëŸ‰', 'ëª¨ë°”ì¼ê²€ìƒ‰ëŸ‰', 'ì›”ê°„ì´ê²€ìƒ‰ëŸ‰', 'ë¬¸ì„œìˆ˜', 'ê²½ìŸìœ¨', 
                         'ì¶”ì²œì œëª©1', 'ì¶”ì²œì œëª©2', 'ì¶”ì²œì œëª©3', 'ì¶”ì²œì œëª©4', 'ì¶”ì²œì œëª©5']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for data in sorted_data:
                writer.writerow(data)
        
        print(f"\nê²°ê³¼ê°€ {filename} íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ì´ {len(sorted_data)}ê°œì˜ ê³ ìœ  í‚¤ì›Œë“œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"CSV íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # API ì¸ì¦ ì •ë³´
    API_KEY = "01000000005d84e573bf51b1af97bd55d80b4d161478ae089b8b686db032a1b9d3addb3ad3"
    SECRET_KEY = "AQAAAABdhOVzv1Gxr5e9VdgLTRYUk3Gl94kmw7v5tmIXJb3Rrg=="
    CUSTOMER_ID = 3495013
    
    # ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    print("=" * 60)
    print("ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API í‚¤ì›Œë“œ ê²€ìƒ‰ëŸ‰ ì¡°íšŒ ë° ë¸”ë¡œê·¸ ì œëª© ì¶”ì²œ ë„êµ¬")
    print("=" * 60)
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
    if len(sys.argv) >= 2:
        hint_keywords = sys.argv[1]
    else:
        print("\nê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        print("ì˜ˆì‹œ: ê½ƒë°°ë‹¬, flower, ê½ƒë°°ë‹¬,flower,í™”í™˜")
        hint_keywords = input("í‚¤ì›Œë“œ: ").strip()
        
        if not hint_keywords:
            print("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            sys.exit(1)
    
    # ì¡°íšŒí•  í‚¤ì›Œë“œ ê°œìˆ˜ ì…ë ¥
    try:
        max_keywords = int(input(f"\nëª‡ ê°œì˜ í‚¤ì›Œë“œë¥¼ ì¡°íšŒí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ê¸°ë³¸ê°’: 20): ") or "20")
    except ValueError:
        max_keywords = 20
    
    print(f"\ní‚¤ì›Œë“œ ê²€ìƒ‰ ì¤‘: {hint_keywords}")
    print(f"ìµœëŒ€ {max_keywords}ê°œì˜ í‚¤ì›Œë“œë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
    print("ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ í‚¤ì›Œë“œì™€ ê²€ìƒ‰ëŸ‰ì„ ì¡°íšŒí•©ë‹ˆë‹¤...")
    print("ê° í‚¤ì›Œë“œë³„ë¡œ ë¸”ë¡œê·¸ ì œëª© 5ê°œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤...\n")
    
    # API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    api = NaverSearchAdAPI(API_KEY, SECRET_KEY, CUSTOMER_ID)
    
    # ëª¨ë“  í‚¤ì›Œë“œ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    all_keyword_data = []
    searched_keywords = set()  # ì´ë¯¸ ê²€ìƒ‰í•œ í‚¤ì›Œë“œ ì¶”ì 
    initial_keywords = [kw.strip() for kw in hint_keywords.split(',')]  # ì´ˆê¸° í‚¤ì›Œë“œë“¤
    
    # ì´ˆê¸° í‚¤ì›Œë“œë“¤ë¡œë§Œ ê²€ìƒ‰ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
    for i, current_keyword in enumerate(initial_keywords):
        # ëª©í‘œ ê°œìˆ˜ì— ë„ë‹¬í–ˆìœ¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ
        if len(all_keyword_data) >= max_keywords:
            print(f"\nğŸ¯ ëª©í‘œ í‚¤ì›Œë“œ ê°œìˆ˜ {max_keywords}ê°œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤!")
            break
            
        if current_keyword in searched_keywords:
            print(f"ì´ë¯¸ ê²€ìƒ‰í•œ í‚¤ì›Œë“œ '{current_keyword}' ê±´ë„ˆë›°ê¸°")
            continue
        
        print(f"\n[{i+1}íšŒì°¨] í‚¤ì›Œë“œ ê²€ìƒ‰: {current_keyword}")
        searched_keywords.add(current_keyword)
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤í–‰
        result = api.search_keywords(current_keyword, show_detail=1)
        
        if result:
            # ë‚¨ì€ ìŠ¬ë¡¯ ê³„ì‚°
            remaining_slots = max_keywords - len(all_keyword_data)
            
            # ë‚¨ì€ ìŠ¬ë¡¯ë§Œí¼ë§Œ ì²˜ë¦¬
            keyword_data = get_keyword_data(result, remaining_slots)
            
            if keyword_data:
                all_keyword_data.extend(keyword_data)
                
                # í˜„ì¬ ê²°ê³¼ í‘œì‹œ
                display_keyword_results(keyword_data, current_keyword)
                
                print(f"í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ í‚¤ì›Œë“œ: {len(all_keyword_data)}ê°œ")
                
                # ëª©í‘œ ê°œìˆ˜ì— ë„ë‹¬í–ˆìœ¼ë©´ ì¢…ë£Œ
                if len(all_keyword_data) >= max_keywords:
                    print(f"\nğŸ¯ ëª©í‘œ í‚¤ì›Œë“œ ê°œìˆ˜ {max_keywords}ê°œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤!")
                    break
            else:
                print(f"'{current_keyword}'ì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            print(f"'{current_keyword}' ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
        time.sleep(0.5)
    
    # ìµœì¢… ê²°ê³¼ ì €ì¥
    if all_keyword_data:
        # íŒŒì¼ëª… ìƒì„± (ì…ë ¥ í‚¤ì›Œë“œ ê¸°ë°˜)
        base_filename = hint_keywords.replace(',', '_').replace(' ', '_')
        filename = f"{base_filename}_ì œëª©ì¶”ì²œ.xlsx"
        
        print(f"\n{'='*60}")
        print("ğŸ“Š ìµœì¢… ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ ì¤‘...")
        save_to_excel(all_keyword_data, filename)
        
        # ìµœì¢… í†µê³„
        print(f"\n{'='*60}")
        print("âœ… ê²€ìƒ‰ ì™„ë£Œ!")
        print(f"ğŸ“ˆ ì´ ê²€ìƒ‰í•œ í‚¤ì›Œë“œ: {len(searched_keywords)}ê°œ")
        print(f"ğŸ“Š ì´ ìˆ˜ì§‘ëœ ë°ì´í„°: {len(all_keyword_data)}ê°œ")
        print(f"ğŸ“ ì´ ì¶”ì²œ ì œëª©: {len(all_keyword_data) * 5}ê°œ")
        print(f"ğŸ’¾ ì €ì¥ëœ íŒŒì¼: {filename}")
        print(f"ğŸ“ íŒŒì¼ ìœ„ì¹˜: {os.path.abspath(filename)}")
        print("\nğŸ¯ ì—‘ì…€ íŒŒì¼ì—ì„œ ê° í‚¤ì›Œë“œë³„ ì¶”ì²œ ì œëª© 5ê°œë¥¼ í™•ì¸í•˜ì„¸ìš”!")
    else:
        print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
